#!/usr/bin/env node

/**
 * Test script for comprehensive voice analysis system
 * Tests the complete end-to-end voice processing pipeline
 */

require('dotenv').config();
const WebSocket = require('ws');
const voiceAnalysisService = require('./src/services/voiceAnalysisService');
const logger = require('./src/utils/logger');

// Test configuration
const BACKEND_URL = 'ws://localhost:3001/ws';
const DEMO_CALL_ID = 'demo-call-test-' + Date.now();

async function testVoiceAnalysisSystem() {
  console.log('üéØ Testing Complete Voice Analysis System');
  console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');

  try {
    // Step 1: Test Voice Analysis Service directly
    console.log('\nüìã Step 1: Testing Voice Analysis Service...');
    
    const audioBuffer = Buffer.from('test-audio-data-for-comprehensive-analysis');
    const audioMetrics = {
      volume: 80,
      clarity: 75,
      duration: 5.2,
      sampleRate: 44100,
      bitRate: 128000
    };

    const analysisResult = await voiceAnalysisService.processVoiceInput(audioBuffer, 'webm', audioMetrics);
    
    console.log('‚úÖ Voice Analysis Service Results:');
    console.log('   üìù Transcription:', analysisResult.transcription.text);
    console.log('   üéØ Confidence:', analysisResult.transcription.confidence + '%');
    console.log('   üé≠ Sentiment:', analysisResult.analysis.sentiment.overall);
    console.log('   üòä Emotion:', analysisResult.analysis.emotion.primary);
    console.log('   üéØ Intent:', analysisResult.analysis.intent.category);
    console.log('   üîä Audio Quality:', analysisResult.analysis.audioMetrics.overallQuality);

    // Step 2: Test WebSocket Connection
    console.log('\nüìã Step 2: Testing WebSocket Connection...');
    
    const ws = new WebSocket(BACKEND_URL);
    
    await new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('WebSocket connection timeout'));
      }, 5000);

      ws.on('open', () => {
        clearTimeout(timeout);
        console.log('‚úÖ WebSocket connected successfully');

        // Join the demo call room
        const joinMessage = {
          type: 'join_demo_call',
          callId: DEMO_CALL_ID,
          token: 'demo-token',
          isDemoMode: true
        };
        ws.send(JSON.stringify(joinMessage));

        // Wait for join confirmation
        const joinTimeout = setTimeout(() => {
          reject(new Error('Demo call join timeout'));
        }, 3000);

        const joinHandler = (data) => {
          try {
            const message = JSON.parse(data.toString());
            if (message.type === 'joined_demo_call') {
              clearTimeout(joinTimeout);
              ws.removeListener('message', joinHandler);
              console.log('‚úÖ Joined demo call successfully');
              resolve();
            }
          } catch (error) {
            // Ignore parsing errors
          }
        };

        ws.on('message', joinHandler);
      });

      ws.on('error', (error) => {
        clearTimeout(timeout);
        reject(error);
      });
    });

    // Step 3: Test Voice Input Processing via WebSocket
    console.log('\nüìã Step 3: Testing Voice Input via WebSocket...');
    
    const voiceInputMessage = {
      type: 'voice_input',
      callId: DEMO_CALL_ID,
      audioData: audioBuffer.toString('base64'),
      format: 'webm',
      audioMetrics: audioMetrics
    };

    // Listen for voice analysis response
    const analysisResponse = await new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('Voice analysis response timeout'));
      }, 10000);

      ws.on('message', (data) => {
        try {
          const message = JSON.parse(data.toString());
          if (message.type === 'voice_analysis') {
            clearTimeout(timeout);
            resolve(message);
          }
        } catch (error) {
          // Ignore parsing errors for other message types
        }
      });

      // Send voice input
      ws.send(JSON.stringify(voiceInputMessage));
    });

    console.log('‚úÖ WebSocket Voice Analysis Results:');
    console.log('   üìù Transcription:', analysisResponse.data.transcription.text);
    console.log('   üé≠ Sentiment:', analysisResponse.data.analysis.sentiment.overall);
    console.log('   üòä Emotion:', analysisResponse.data.analysis.emotion.primary);
    console.log('   üéØ Intent:', analysisResponse.data.analysis.intent.category);

    // Step 4: Test Real-time Processing Performance
    console.log('\nüìã Step 4: Testing Real-time Processing Performance...');
    
    const startTime = Date.now();
    
    // Process multiple voice inputs rapidly
    const testInputs = [
      { text: 'Hello, I need help with my account', volume: 70, clarity: 80 },
      { text: 'Can you help me reset my password?', volume: 85, clarity: 75 },
      { text: 'Thank you for your assistance', volume: 75, clarity: 85 }
    ];

    const results = [];
    for (const input of testInputs) {
      const testBuffer = Buffer.from(input.text);
      const testMetrics = {
        volume: input.volume,
        clarity: input.clarity,
        duration: 3.0,
        sampleRate: 44100,
        bitRate: 128000
      };

      const result = await voiceAnalysisService.processVoiceInput(testBuffer, 'webm', testMetrics);
      results.push(result);
    }

    const processingTime = Date.now() - startTime;
    console.log(`‚úÖ Processed ${testInputs.length} voice inputs in ${processingTime}ms`);
    console.log(`   ‚ö° Average processing time: ${Math.round(processingTime / testInputs.length)}ms per input`);

    // Step 5: Verify Analysis Quality
    console.log('\nüìã Step 5: Verifying Analysis Quality...');
    
    let qualityScore = 0;
    results.forEach((result, index) => {
      const expectedSentiments = ['neutral', 'neutral', 'positive'];
      const expectedEmotions = ['neutral', 'neutral', 'satisfied'];
      
      if (result.analysis.sentiment.overall === expectedSentiments[index]) qualityScore += 1;
      if (result.analysis.emotion.primary === expectedEmotions[index]) qualityScore += 1;
      if (result.transcription.confidence >= 80) qualityScore += 1;
    });

    const qualityPercentage = Math.round((qualityScore / (testInputs.length * 3)) * 100);
    console.log(`‚úÖ Analysis Quality Score: ${qualityPercentage}%`);

    // Close WebSocket
    ws.close();

    // Final Results
    console.log('\nüéâ COMPREHENSIVE VOICE ANALYSIS SYSTEM TEST COMPLETE');
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log('‚úÖ Voice Analysis Service: WORKING');
    console.log('‚úÖ WebSocket Communication: WORKING');
    console.log('‚úÖ Real-time Processing: WORKING');
    console.log('‚úÖ Analysis Quality: ' + qualityPercentage + '%');
    console.log('‚úÖ Gemini 2.5 Flash Integration: WORKING');
    console.log('\nüöÄ The voice analysis system is ready for production use!');

  } catch (error) {
    console.error('\n‚ùå Test failed:', error.message);
    console.error('Stack trace:', error.stack);
    process.exit(1);
  }
}

// Run the test
if (require.main === module) {
  testVoiceAnalysisSystem()
    .then(() => {
      console.log('\n‚úÖ All tests passed successfully!');
      process.exit(0);
    })
    .catch((error) => {
      console.error('\n‚ùå Test suite failed:', error.message);
      process.exit(1);
    });
}

module.exports = { testVoiceAnalysisSystem };
